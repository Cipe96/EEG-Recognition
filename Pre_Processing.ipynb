{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VUVmRb8LmP8C",
        "pGD03pQZoiLT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cipe96/EEG-Recognition/blob/main/Pre_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=6>**EEG Recognition: Pre-Processing**</font>\n",
        "</br><font size=3>*Marco Cipollina, Riccardo Era*</font>\n"
      ],
      "metadata": {
        "id": "2e-lgBGFxbDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"font-size:4px;\" align=\"justify\">In questo notebook viene svolta l'analisi del dataset composto dalla sola prima run del famoso \"EEG Motor Movement/Imagery\". È possibile trovare informazioni dettagliate riguardo il dataset originale al seguente <a href=\"https://physionet.org/content/eegmmidb/1.0.0/\">link</a>.</p>\n",
        "<p style=\"font-size:4px;\" align=\"justify\">Oltre che poter osservare gli elementi principali, è possibile svolgere delle analisi specifiche a relativi campioni e volontari.</p>"
      ],
      "metadata": {
        "id": "IsDiDI8VR-7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=4>**Indice:**</font>\n",
        "*   [Import librerie](#1)\n",
        "*   [Downloads](#2)\n",
        "*   [Pre-Procesing](#3)"
      ],
      "metadata": {
        "id": "0M8yjfwYmIr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"1\"></a>\n",
        "# **Import librerie**"
      ],
      "metadata": {
        "id": "VUVmRb8LmP8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniziamo installando la libreria MNE, essenziale per l'analisi di dati EEG grazie alla sua gestione di file in formato EDF."
      ],
      "metadata": {
        "id": "vpVUDuFzViQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# evita l' output a video\n",
        "!pip install mne"
      ],
      "metadata": {
        "id": "gk46T_kQVNaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importiamo le librerie e montiamo Google Drive per garantire l'accesso agli altri file."
      ],
      "metadata": {
        "id": "9c3Ma2Rlmiac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sys\n",
        "import mne\n",
        "import os"
      ],
      "metadata": {
        "id": "MJBltQXPmXAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALBNMDMymhK7",
        "outputId": "b915df81-23b8-4a70-d6d1-b59287fff9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"2\"></a>\n",
        "# **Download**"
      ],
      "metadata": {
        "id": "LyPbHzAnsaYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Percorso della cartella del progetto su Google Drive:\n",
        "\n",
        "#@markdown Se la cartella del progetto si trova nella root di Drive, scrivere solo il suo nome:\n",
        "PERCORSO_DRIVE = \"EEG Recognition\" #@param {type:\"string\"}\n",
        "\n",
        "PERCORSO_DRIVE = '/content/drive/MyDrive/' + PERCORSO_DRIVE"
      ],
      "metadata": {
        "id": "Lez481oNm5Lm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(PERCORSO_DRIVE)                       # ci permetterà di importare le funzioni presenti in altri file\n",
        "from shared_utilities import download_dataset"
      ],
      "metadata": {
        "id": "H5d-7KgaqsqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scarichiamo dal file \"EEG_Motor_Movement-Imagery_R01_ID.json\" l'ID necessario per il download del dataset."
      ],
      "metadata": {
        "id": "BCt6vJjMq99U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(PERCORSO_DRIVE + '/EEG_Motor_Movement-Imagery_R01_ID.json', 'r') as file:\n",
        "  config = json.load(file)\n",
        "\n",
        "DATASET_ID = config['DATASET_ID']"
      ],
      "metadata": {
        "id": "RQOIZLr-sI76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Impostazioni download\n",
        "\n",
        "#@markdown Nome del zip dataset post download:\n",
        "DATASET_NAME = 'EEG_Motor_Movement-Imagery.zip' #@param {type:\"string\"}\n",
        "\n",
        "download_dataset(DATASET_ID, DATASET_NAME, msg=True)"
      ],
      "metadata": {
        "id": "RU9KJSFBscEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226e7040-9ffc-45b0-eafe-9ae624e4ac28",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WwuAh25Jfx-I8rY3vFGyXiI79YfLYUpH\n",
            "From (redirected): https://drive.google.com/uc?id=1WwuAh25Jfx-I8rY3vFGyXiI79YfLYUpH&confirm=t&uuid=6e88ffc4-dd26-483b-9109-a60b460016cf\n",
            "To: /content/EEG_Motor_Movement-Imagery.zip\n",
            "100%|██████████| 76.6M/76.6M [00:05<00:00, 13.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File scaricato e salvato come EEG_Motor_Movement-Imagery.zip!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dopo aver scaricato il dataset lo unzippiamo ed eliminiamo i file txt e la cartella sample_data creata automaticamente da Colab."
      ],
      "metadata": {
        "id": "hokXkJe7s-RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "! unzip \"{DATASET_NAME}\"              # unzippa il file zip\n",
        "! rm /content/AMSL/*.txt              # elimina i file txt\n",
        "! rm -r /content/sample_data          # elimina la cartella di default di Colab"
      ],
      "metadata": {
        "id": "0_MrmgwXs_Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "pGD03pQZoiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mne.preprocessing import ica\n",
        "train = []\n",
        "label_tr = []\n",
        "val = []\n",
        "label_val = []\n",
        "test = []\n",
        "label_ts = []\n",
        "classe = 0\n",
        "\n",
        "# Patch length --> 240 samples == 1.5 second\n",
        "\n",
        "l_patch = 240\n",
        "\n",
        "# Split into 5 frequency bands\n",
        "\n",
        "high = {'alpha' : 13, 'beta' : 30, 'delta' : 4, 'gamma' : 40, 'theta' : 8, 'broadband' : None } # High frequencies\n",
        "low = {'alpha' : 8, 'beta' : 13, 'delta' : 0.5, 'gamma' : 30, 'theta' : 4, 'broadband' : 1 } # Low frequencies\n",
        "\n",
        "sec = 60 / 1.5 # samples taken in 1.5 seconds\n",
        "ntr = sec * 0.7  # train set window\n",
        "nvd = sec * 0.15 # validation set window\n",
        "nts = sec * 0.15 # test set window\n",
        "\n",
        "for eeg in files[:len(classi)]:\n",
        "\n",
        "  raw = mne.io.read_raw_edf(input_fname = '/content/EEG_T0/'+eeg, preload = True, verbose = 'CRITICAL')\n",
        "  raw.filter(l_freq = low['broadband'], h_freq = high['broadband'], n_jobs = 8, verbose = 'CRITICAL')\n",
        "\n",
        "  # Impostiamo il riferimento medio\n",
        "  raw.set_eeg_reference('average', projection=True)\n",
        "\n",
        "  # Creiamo un'istanza ICA e la adattiamo ai dati\n",
        "  ica = mne.preprocessing.ICA(n_components=64, random_state=97, max_iter=800)\n",
        "  ica.fit(raw)\n",
        "\n",
        "  # Identifica i componenti associati ai movimenti oculari (ad es. con canale EOG)\n",
        "  eog_indices, eog_scores = ica.find_bads_eog(raw)  # Usa canali EOG, se presenti\n",
        "  ica.exclude = eog_indices  # Escludi i componenti identificati come rumore\n",
        "\n",
        "  # Identifichiamo automaticamente i componenti associati ai movimenti oculari\n",
        "  ica.detect_artifacts(raw)\n",
        "\n",
        "  # Rimuoviamo i componenti identificati\n",
        "  raw_ica = ica.apply(raw.copy())\n",
        "\n",
        "  rec = raw_ica.get_data()\n",
        "  h=0\n",
        "\n",
        "  while(h < l_patch*ntr):\n",
        "    train.append(rec[:,h:h+l_patch]) # train set\n",
        "    label_tr.append(classe)\n",
        "    h=h+l_patch\n",
        "\n",
        "  # RICORDA DI FARE EARLY STOP     D O P O\n",
        "  while(h < (ntr+nvd)*l_patch):\n",
        "    val.append(rec[:,h:h+l_patch]) # validation set\n",
        "    label_val.append(classe)\n",
        "    h=h+l_patch\n",
        "\n",
        "  while(h < l_patch*(ntr+nvd+nts) and h + l_patch <= rec.shape[1]):\n",
        "    test.append(rec[:,h:h+l_patch]) # test set\n",
        "    label_ts.append(classe)\n",
        "    h=h+l_patch\n",
        "\n",
        "  classe = classe + 1\n"
      ],
      "metadata": {
        "id": "oaT0dGGM0avV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "889bd20f-b028-435a-e25a-5ab59bd59d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG channel type selected for re-referencing\n",
            "Adding average EEG reference projection.\n",
            "1 projection items deactivated\n",
            "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
            "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
            "Selecting by number: 15 components\n",
            "Fitting ICA took 0.7s.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ICA' object has no attribute 'detect_artifacts'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-bb072547a2e0>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m# Identifichiamo automaticamente i componenti associati ai movimenti oculari\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Rimuoviamo i componenti identificati\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ICA' object has no attribute 'detect_artifacts'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_array = np.array(train)  # Converti la lista train in un array NumPy\n",
        "print(train_array.shape)\n",
        "val_array = np.array(val)  # Converti la lista train in un array NumPy\n",
        "print(val_array.shape)\n",
        "test_array = np.array(test)  # Converti la lista train in un array NumPy\n",
        "print(test_array.shape)\n",
        "\n",
        "label_tr = np.array(label_tr)\n",
        "print(label_tr.shape)\n",
        "label_val = np.array(label_val)\n",
        "print(label_val.shape)\n",
        "label_ts = np.array(label_ts)\n",
        "print(label_ts.shape)\n",
        "print(rec.shape)"
      ],
      "metadata": {
        "id": "bnZnXSP4yq35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(9600 * 240) / 109 = 4360 /n\n",
        "4360 * 0.7 = 3052 /n\n",
        "4360 * 0.15 = 654"
      ],
      "metadata": {
        "id": "j4x4854X_LJi"
      }
    }
  ]
}